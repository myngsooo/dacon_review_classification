{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쇼핑몰 리뷰 평점 분류 경진대회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datasets\n",
    "import glob\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"klue/bert-base\"# \"kykim/bert-kor-base\" #\"kykim/electra-kor-base\" #\"klue/roberta-large\" # \"klue/bert-base\", \"klue/bert-large\", \"klue/roberta-base\"\n",
    "batch_size = 200\n",
    "learning_rate = 2e-5\n",
    "NUM_EPOCH = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-24f77f946c60edab\n",
      "Reusing dataset csv (/home/uj-user/.cache/huggingface/datasets/csv/default-24f77f946c60edab/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57378937fda84737b35271e957cae618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "raw_train = pd.read_csv('./dataset/train.csv')\n",
    "raw_test = load_dataset('csv', data_files='./dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviews</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13412</th>\n",
       "      <td>13412</td>\n",
       "      <td>잠자리가 추워서 샀는데 이거때매 회사 지각 몇번했습니다</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15013</th>\n",
       "      <td>15013</td>\n",
       "      <td>티비서하두멘보샤멘보샤해서궁금해서먹어봤습니다.첨먹엇을땐맛있었는데느끼한맛이강합니다</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>13297</td>\n",
       "      <td>정말튼튼하고 나무재질도 좋습니다 다리부분도 튼튼해요 의자도 너무좋네요 배송은주문제작...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18720</th>\n",
       "      <td>18720</td>\n",
       "      <td>배송시까지 일주일걸립니다 당일도착 3일간 오고 결국 일주일뒤에 도착했습니다.통화해보...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20535</th>\n",
       "      <td>20535</td>\n",
       "      <td>손때및 기스가 잘나요!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11067</th>\n",
       "      <td>11067</td>\n",
       "      <td>이게 바지락인지 재첩인지..ㅠ 백원짜리만하네요...여태 여러군데서 사봤는데 가장 작...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>4319</td>\n",
       "      <td>xl 사려다 품절이여서 프리사이즈 주문했는데 많이 후회되네요. (사이즈 후회) 1....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>12279</td>\n",
       "      <td>고양이집 만드는데 썻습니다</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>7486</td>\n",
       "      <td>많이 비치치 않고 길이감도 적당합니다.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>6889</td>\n",
       "      <td>철제라 너무 무겁고 혼자 하기는 너무 어렵고 세로 길이가 타이트하면 조립이 어려워 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24975 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            reviews  target\n",
       "13412  13412                     잠자리가 추워서 샀는데 이거때매 회사 지각 몇번했습니다       5\n",
       "15013  15013        티비서하두멘보샤멘보샤해서궁금해서먹어봤습니다.첨먹엇을땐맛있었는데느끼한맛이강합니다       2\n",
       "13297  13297  정말튼튼하고 나무재질도 좋습니다 다리부분도 튼튼해요 의자도 너무좋네요 배송은주문제작...       5\n",
       "18720  18720  배송시까지 일주일걸립니다 당일도착 3일간 오고 결국 일주일뒤에 도착했습니다.통화해보...       2\n",
       "20535  20535                                       손때및 기스가 잘나요!       2\n",
       "...      ...                                                ...     ...\n",
       "11067  11067  이게 바지락인지 재첩인지..ㅠ 백원짜리만하네요...여태 여러군데서 사봤는데 가장 작...       2\n",
       "4319    4319  xl 사려다 품절이여서 프리사이즈 주문했는데 많이 후회되네요. (사이즈 후회) 1....       2\n",
       "12279  12279                                     고양이집 만드는데 썻습니다       5\n",
       "7486    7486                              많이 비치치 않고 길이감도 적당합니다.       5\n",
       "6889    6889  철제라 너무 무겁고 혼자 하기는 너무 어렵고 세로 길이가 타이트하면 조립이 어려워 ...       2\n",
       "\n",
       "[24975 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid = train_test_split(raw_train, random_state=2022, stratify=raw_train['target'], test_size=0.001)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13412</th>\n",
       "      <td>잠자리가 추워서 샀는데 이거때매 회사 지각 몇번했습니다</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15013</th>\n",
       "      <td>티비서하두멘보샤멘보샤해서궁금해서먹어봤습니다.첨먹엇을땐맛있었는데느끼한맛이강합니다</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>정말튼튼하고 나무재질도 좋습니다 다리부분도 튼튼해요 의자도 너무좋네요 배송은주문제작...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18720</th>\n",
       "      <td>배송시까지 일주일걸립니다 당일도착 3일간 오고 결국 일주일뒤에 도착했습니다.통화해보...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20535</th>\n",
       "      <td>손때및 기스가 잘나요!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11067</th>\n",
       "      <td>이게 바지락인지 재첩인지..ㅠ 백원짜리만하네요...여태 여러군데서 사봤는데 가장 작...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>xl 사려다 품절이여서 프리사이즈 주문했는데 많이 후회되네요. (사이즈 후회) 1....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>고양이집 만드는데 썻습니다</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>많이 비치치 않고 길이감도 적당합니다.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>철제라 너무 무겁고 혼자 하기는 너무 어렵고 세로 길이가 타이트하면 조립이 어려워 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  target\n",
       "13412                     잠자리가 추워서 샀는데 이거때매 회사 지각 몇번했습니다       5\n",
       "15013        티비서하두멘보샤멘보샤해서궁금해서먹어봤습니다.첨먹엇을땐맛있었는데느끼한맛이강합니다       2\n",
       "13297  정말튼튼하고 나무재질도 좋습니다 다리부분도 튼튼해요 의자도 너무좋네요 배송은주문제작...       5\n",
       "18720  배송시까지 일주일걸립니다 당일도착 3일간 오고 결국 일주일뒤에 도착했습니다.통화해보...       2\n",
       "20535                                       손때및 기스가 잘나요!       2\n",
       "...                                                  ...     ...\n",
       "11067  이게 바지락인지 재첩인지..ㅠ 백원짜리만하네요...여태 여러군데서 사봤는데 가장 작...       2\n",
       "4319   xl 사려다 품절이여서 프리사이즈 주문했는데 많이 후회되네요. (사이즈 후회) 1....       2\n",
       "12279                                     고양이집 만드는데 썻습니다       5\n",
       "7486                               많이 비치치 않고 길이감도 적당합니다.       5\n",
       "6889   철제라 너무 무겁고 혼자 하기는 너무 어렵고 세로 길이가 타이트하면 조립이 어려워 ...       2\n",
       "\n",
       "[24975 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:,['reviews', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_train_dataset = Dataset.from_pandas(train[['reviews', 'target']], preserve_index=False)\n",
    "raw_valid_dataset = Dataset.from_pandas(valid[['reviews', 'target']], preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['reviews', 'target'],\n",
       "    num_rows: 24975\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['reviews', 'target'],\n",
       "        num_rows: 24975\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['reviews', 'target'],\n",
       "        num_rows: 25\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'reviews'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train, valid= raw_train['train'].train_test_split(test_size=0.1).values()\n",
    "review_dataset = datasets.DatasetDict({'train': raw_train_dataset, 'valid': raw_valid_dataset, 'test': raw_test['train']})\n",
    "review_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_function at 0x7fc145322e50> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['조아', '##요', '처음', '##구', '##입', '싸', '##게', '##햇', '##어요']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48774c55f8674181af91f92968f5cefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5fe52b5ad84ebf822d17ca994f316c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd333df9d9547b1810122b23dd3b25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(tokenizer.tokenize(train['reviews'][0]))\n",
    "\n",
    "def preprocess_function(example):\n",
    "    return tokenizer(example[\"reviews\"], truncation=True)\n",
    "    \n",
    "tokenized_datasets = review_dataset.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['reviews', 'target', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 24975\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['reviews', 'target', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'reviews', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 정보 제거\n",
    "tokenized_datasets['train'] = tokenized_datasets['train'].remove_columns([\"reviews\"])\n",
    "tokenized_datasets['valid'] = tokenized_datasets['valid'].remove_columns([\"reviews\"])\n",
    "tokenized_datasets['test'] = tokenized_datasets['test'].remove_columns([\"id\", \"reviews\"])\n",
    "\n",
    "# 타겟 이름 변경\n",
    "tokenized_datasets['train'] = tokenized_datasets['train'].rename_column(\"target\", \"labels\")\n",
    "tokenized_datasets['valid'] = tokenized_datasets['valid'].rename_column(\"target\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator)\n",
    "valid_dataloader = DataLoader(tokenized_datasets[\"valid\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"test\"], shuffle=False, batch_size=batch_size, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([200]),\n",
       " 'input_ids': torch.Size([200, 73]),\n",
       " 'token_type_ids': torch.Size([200, 73]),\n",
       " 'attention_mask': torch.Size([200, 73])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f1652b5988469da6b951682c42b018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=6) # 편의상 6으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uj-user/miniconda3/envs/review/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler, AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_training_steps = NUM_EPOCH * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ad2032ea6c438587f7edd15f3ad3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    model.save_pretrained(f\"./aug_result/{MODEL_NAME}/{epoch+1}\")\n",
    "    tokenizer.save_pretrained(f\"./aug_result/{MODEL_NAME}/{epoch+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "def validation_model(model):\n",
    "    accuracy = Accuracy()\n",
    "\n",
    "    prediction_list_valid = []\n",
    "    target_list_valid = []\n",
    "\n",
    "    model.eval()\n",
    "    for batch in valid_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1).cpu()\n",
    "        targets = batch['labels'].cpu()\n",
    "\n",
    "        prediction_list_valid.extend(predictions)\n",
    "        target_list_valid.extend(targets)\n",
    "        #print(accuracy(predictions, targets)) # 매 batch 마다의 Accuracy\n",
    "\n",
    "    print(f'valid acc: {accuracy(torch.IntTensor(prediction_list_valid), torch.IntTensor(target_list_valid)).cpu().tolist():.4f}')\n",
    "\n",
    "    \n",
    "def validation_train_model(model):\n",
    "    accuracy = Accuracy()\n",
    "\n",
    "    prediction_list_valid = []\n",
    "    target_list_valid = []\n",
    "\n",
    "    model.eval()\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1).cpu()\n",
    "        targets = batch['labels'].cpu()\n",
    "\n",
    "        prediction_list_valid.extend(predictions)\n",
    "        target_list_valid.extend(targets)\n",
    "        #print(accuracy(predictions, targets)) # 매 batch 마다의 Accuracy\n",
    "\n",
    "    print(f'train acc: {accuracy(torch.IntTensor(prediction_list_valid), torch.IntTensor(target_list_valid)).cpu().tolist():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:model >> ./aug_result/klue/bert-base/1\n",
      "valid acc: 0.7600\n",
      "2:model >> ./aug_result/klue/bert-base/2\n",
      "valid acc: 0.7600\n",
      "3:model >> ./aug_result/klue/bert-base/3\n",
      "valid acc: 0.7600\n",
      "4:model >> ./aug_result/klue/bert-base/4\n",
      "valid acc: 0.7600\n",
      "5:model >> ./aug_result/klue/bert-base/5\n",
      "valid acc: 0.7600\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델을 활용하여 Validation 데이터셋에서 성능확인\n",
    "save_paths = sorted(glob(f\"./aug_result/{MODEL_NAME}/*\"))\n",
    "for i, save_path in enumerate(save_paths):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=6).to(device)\n",
    "    print(f\"{i+1}:model >> {save_path}\")\n",
    "    validation_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:model >> ./aug_result/klue/bert-base/1\n",
      "train acc: 0.7081\n",
      "2:model >> ./aug_result/klue/bert-base/2\n",
      "train acc: 0.7240\n",
      "3:model >> ./aug_result/klue/bert-base/3\n",
      "train acc: 0.7412\n",
      "4:model >> ./aug_result/klue/bert-base/4\n",
      "train acc: 0.7493\n",
      "5:model >> ./aug_result/klue/bert-base/5\n",
      "train acc: 0.7563\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델을 활용하여 Train 데이터셋에서 성능확인\n",
    "save_paths = sorted(glob(f\"./aug_result/{MODEL_NAME}/*\"))\n",
    "for i, save_path in enumerate(save_paths):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=6).to(device)\n",
    "    print(f\"{i+1}:model >> {save_path}\")\n",
    "    validation_train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 Evaluation 및 Submission 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_submit_model(model, eval_epoch):\n",
    "    prediction_list = []\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        prediction_list.extend(predictions.cpu().tolist())\n",
    "\n",
    "    submission = pd.read_csv(\"dataset/sample_submission.csv\")\n",
    "    submission[\"target\"] = prediction_list\n",
    "    submission.to_csv(f\"./submission/submission_{MODEL_NAME.replace('/', '_')}_{eval_epoch}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:model >> ./aug_result/klue/bert-base/1\n",
      "2:model >> ./aug_result/klue/bert-base/2\n",
      "3:model >> ./aug_result/klue/bert-base/3\n",
      "4:model >> ./aug_result/klue/bert-base/4\n",
      "5:model >> ./aug_result/klue/bert-base/5\n"
     ]
    }
   ],
   "source": [
    "save_paths = sorted(glob(f\"./aug_result/{MODEL_NAME}/*\"))\n",
    "for i, save_path in enumerate(save_paths):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=6).to(device)\n",
    "    print(f\"{i+1}:model >> {save_path}\")\n",
    "    evaluate_submit_model(model, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('review': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62924353be2d6998b04c83d0e210e35559f7d4fed57bef9b7971c9483623c7fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
