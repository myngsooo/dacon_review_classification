{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쇼핑몰 리뷰 평점 분류 경진대회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pororo import Pororo\n",
    "\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datasets\n",
    "import glob\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data Augmentation (BackTranslation)\n",
    "데이터셋을 Augmentation하기 위한 방법으로, Pororo API를 활용하여 한국어->영어->한국어, 한국어->일본어->한국어 두가지 방법을 진행하였습니다.  \n",
    "총 데이터셋이 50000개이므로 생각보다 시간이 걸립니다. 하나의 번역결과를 얻는데 평균 10초정도의 시간이 걸립니다. (GPU를 제대로 활용하지 못하는듯 합니다.)  \n",
    "그래서 Train(영어), Test(영어), Train(일본어), Test(일본어) 4개로 나눠서 Python파일로 실행하였습니다. (25000*10초) 대략 3일정도 걸립니다..  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 및 데이터 로드\n",
    "nmt = Pororo(task=\"translation\", lang=\"multi\")\n",
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "# 텍스트 전처리 (이모지 제거)\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                            \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# 데이터셋 생성 (한국어 -> 이모지 전처리 -> 번역어 -> 한국어)\n",
    "def make_aug_dataset(data, src_lang, tgt_lang):\n",
    "    kor_train_review_list = []\n",
    "    eng_train_review_list = []\n",
    "\n",
    "    for i, text in enumerate(data['reviews']):\n",
    "        text = remove_emoji(text)\n",
    "\n",
    "        en_review = nmt(src=src_lang, text=text, tgt=tgt_lang)\n",
    "        ko_review = nmt(src=tgt_lang, text=en_review, tgt=src_lang)\n",
    "\n",
    "        eng_train_review_list.append(en_review)\n",
    "        kor_train_review_list.append(ko_review)\n",
    "        print(f\"[{i}, \\\"{en_review}\\\", \\\"{ko_review}\\\"],\")\n",
    "    \n",
    "    return kor_train_review_list, eng_train_review_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train(영어) 데이터셋 생성\n",
    "ko_aug_train, en_train = make_aug_dataset(train, \"ko\", \"en\")\n",
    "train['en_ko_review'] = ko_aug_train\n",
    "train['en_review'] = en_train\n",
    "train.to_csv('./dataset/en_aug_train.csv', index=False)\n",
    "\n",
    "# Test(영어) 데이터셋 생성\n",
    "ko_aug_test, en_test = make_aug_dataset(test, \"ko\", \"en\")\n",
    "test['en_ko_review'] = ko_aug_test\n",
    "test['en_review'] = en_test\n",
    "test.to_csv('./dataset/en_aug_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train(일본어) 데이터셋 생성\n",
    "jp_ko_aug_train, jp_train = make_aug_dataset(train, \"ko\", \"ja\")\n",
    "train['jp_ko_review'] = jp_ko_aug_train\n",
    "train['jp_review'] = jp_train\n",
    "train.to_csv('./dataset/jp_aug_train.csv', index=False)\n",
    "\n",
    "# Test(일본어) 데이터셋 생성\n",
    "jp_ko_aug_test, jp_test = make_aug_dataset(test, \"ko\", \"ja\")\n",
    "test['aug_review'] = jp_ko_aug_test\n",
    "test['jp_review'] = jp_test\n",
    "test.to_csv('./dataset/jp_aug_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 4개의 파이썬 파일로 분할하여 실행 후 생성된 4개의 CSV파일을 파이썬 코드로 합쳐주었습니다.  \n",
    "합치는 코드에서 추가되는 Column을 더해서 최종 Augmentation 데이터셋을 생성했습니다. 앞으로는 학습을 진행할때 다음 데이터셋CSV를 활용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 추가된 경우 삭제하는 코드 #index=False를 추가안한경우는 실행안해도 무방\n",
    "def remove_idx():\n",
    "    en_aug = pd.read_csv('./dataset/en_aug_train.csv')\n",
    "    en_aug =en_aug.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])\n",
    "    en_aug.info()\n",
    "    en_aug.to_csv('./dataset/en_aug_train.csv', index=False)\n",
    "\n",
    "# Train데이터셋에서 en, jp 합치는 코드\n",
    "def concat_train_dataset():\n",
    "    en_ko = pd.read_csv('./dataset/en_aug_train.csv')\n",
    "    jp_ko = pd.read_csv('./dataset/jp_aug_train.csv')\n",
    "    en_ko['jp_ko_review'] = jp_ko['jp_ko_review']\n",
    "    en_ko['jp_review'] = jp_ko['jp_review']\n",
    "    en_ko = en_ko[['id', 'target', 'reviews', 'en_ko_review', 'jp_ko_review', 'en_review', 'jp_review']]\n",
    "    en_ko.to_csv('./dataset/train_ko_en_jp.csv', index=False)\n",
    "\n",
    "# Test데이터셋에서 en,jp 합치는 코드\n",
    "def concat_test_dataset():\n",
    "    en_ko = pd.read_csv('./dataset/en_aug_test.csv')\n",
    "    jp_ko = pd.read_csv('./dataset/jp_aug_test.csv')\n",
    "    en_ko['jp_ko_review'] = jp_ko['jp_ko_review']\n",
    "    en_ko['jp_review'] = jp_ko['jp_review']\n",
    "    en_ko = en_ko[['id', 'reviews', 'en_ko_review', 'jp_ko_review', 'en_review', 'jp_review']]\n",
    "    en_ko.to_csv('./dataset/test_ko_en_jp.csv', index=False)\n",
    "\n",
    "#remove_idx()\n",
    "concat_train_dataset()\n",
    "concat_test_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모델 설정\n",
    "\n",
    "\n",
    "각각의 모델을 학습을 진행해서, 아래의 5개의 모델을 데이터셋을 [원본, Aug] 두가지로 나눠 조합하여 앙상블하였습니다.  \n",
    "\"klue/bert-base\",  \"klue/roberta-large\", \"kykim/bert-kor-base\", \"kykim/electra-kor-base\", \"kykim_funnel-kor-base\"  \n",
    "NUM_EPOCH에서 설정된 5에폭동안 매 에폭에 대한 Evaluation CSV를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"klue/bert-base\"# \"klue/roberta-large\" \"kykim/bert-kor-base\" \"kykim/electra-kor-base\" \"kykim_funnel-kor-base\"\n",
    "batch_size = 200\n",
    "learning_rate = 2e-5\n",
    "NUM_EPOCH = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            25000 non-null  int64 \n",
      " 1   target        25000 non-null  int64 \n",
      " 2   reviews       25000 non-null  object\n",
      " 3   en_ko_review  25000 non-null  object\n",
      " 4   jp_ko_review  25000 non-null  object\n",
      " 5   en_review     25000 non-null  object\n",
      " 6   jp_review     25000 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "ko_en_jp = pd.read_csv('./dataset/train_ko_en_jp.csv')\n",
    "ko_en_jp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러온 데이터셋을 확인합니다. 2배로 Augmentation을 진행하여 75000개의 행을 가져야하지만 중복을 최소화하기 위해서, 각각의 Augmentation된 데이터에 대해 같은 행에 두고,  train데이터셋과 validation데이터셋으로 분할하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>reviews</th>\n",
       "      <th>en_ko_review</th>\n",
       "      <th>jp_ko_review</th>\n",
       "      <th>en_review</th>\n",
       "      <th>jp_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13412</th>\n",
       "      <td>13412</td>\n",
       "      <td>5</td>\n",
       "      <td>잠자리가 추워서 샀는데 이거때매 회사 지각 몇번했습니다</td>\n",
       "      <td>차가운 침대 때문에 샀지만 매번 몇 번이나 늦었다.</td>\n",
       "      <td>침대가 추워서 샀는데, 지금까지 회사 지각 몇 번 했습니다.</td>\n",
       "      <td>I bought it because of the cold bed, but I've ...</td>\n",
       "      <td>寝床が寒くて買ったんですが、これまで会社遅刻何回しました。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15013</th>\n",
       "      <td>15013</td>\n",
       "      <td>2</td>\n",
       "      <td>티비서하두멘보샤멘보샤해서궁금해서먹어봤습니다.첨먹엇을땐맛있었는데느끼한맛이강합니다</td>\n",
       "      <td>TV 서버 하든보 샤멘샤에 대해 궁금증이 많았다. 먹었을 때 맛있었지만 맛이 좋았다.</td>\n",
       "      <td>텔레비전사 하드멘보셔먼 보셔먼으로 마음에 먹어 보았습니다.</td>\n",
       "      <td>I've been curious about the TV server Ha Dumen...</td>\n",
       "      <td>テレビサハドメンボシャメンボッシャーで気に食べてみました。 おいしいときはおいしかったのに感...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>13297</td>\n",
       "      <td>5</td>\n",
       "      <td>정말튼튼하고 나무재질도 좋습니다 다리부분도 튼튼해요 의자도 너무좋네요 배송은주문제작...</td>\n",
       "      <td>너는 정말 강하고 목재에 능숙하다 다리가 튼튼하다 그 의자는 너무 좋다 배달은 주문...</td>\n",
       "      <td>정말 튼튼하고 목재도 좋습니다. 다리 부분도 튼튼해요. 의자도 좋군요. 배송은 주문...</td>\n",
       "      <td>You're really strong and you're good with wood...</td>\n",
       "      <td>本当に丈夫で木材もいいです 足の部分も丈夫です 椅子もいいですね 配送は注問題作で2週ぐらい...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18720</th>\n",
       "      <td>18720</td>\n",
       "      <td>2</td>\n",
       "      <td>배송시까지 일주일걸립니다 당일도착 3일간 오고 결국 일주일뒤에 도착했습니다.통화해보...</td>\n",
       "      <td>배달은 일주일이 걸릴 것이다 그는 이날 사흘 동안 도착해 마침내 일주일 후에 도착했...</td>\n",
       "      <td>배송시까지 1주일 걸립니다. 당일 도착한 3일간 와서 결국 1주일 후에 도착했습니다.</td>\n",
       "      <td>It'll take a week for delivery. He arrived for...</td>\n",
       "      <td>配送時まで1週間かかります。 当日着き3日間来て、結局一週間後に着きました。 電話してみたら...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20535</th>\n",
       "      <td>20535</td>\n",
       "      <td>2</td>\n",
       "      <td>손때및 기스가 잘나요!</td>\n",
       "      <td>좋은 시간과 좋은 기회가 될 거야!</td>\n",
       "      <td>손때와 기스가 좋아집니다.</td>\n",
       "      <td>You're gonna have a good time and a good chance!</td>\n",
       "      <td>手垢とギスがよくなります。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11067</th>\n",
       "      <td>11067</td>\n",
       "      <td>2</td>\n",
       "      <td>이게 바지락인지 재첩인지..ㅠ 백원짜리만하네요...여태 여러군데서 사봤는데 가장 작...</td>\n",
       "      <td>아마도 이것은 바지나 재첩일 것이다 그것은 100원 상당이다. 여러 곳에서 샀지만 ...</td>\n",
       "      <td>이게 바지야? 100원 정도군요. 지금까지 여러 곳에서 샀는데, 제일 작은 것처럼.</td>\n",
       "      <td>Maybe this is a pants or a re첩. It's worth a h...</td>\n",
       "      <td>これがズボンか。 百ウォンぐらいですね。 今までいろいろなところで買ってみたのに、一番小さい...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>4319</td>\n",
       "      <td>2</td>\n",
       "      <td>xl 사려다 품절이여서 프리사이즈 주문했는데 많이 후회되네요. (사이즈 후회) 1....</td>\n",
       "      <td>xl을 사다가 다 팔렸기 때문에 무료 사이즈 주문을 했는데 정말 죄송합니다. 원스타...</td>\n",
       "      <td>xl을 사려고 해서 프리사이즈를 주문했는데 너무 분하네요. (사이즈 후회) 1. 1...</td>\n",
       "      <td>I ordered a free-size order because it was sol...</td>\n",
       "      <td>xlを買おうとしたので、プリサイズを注文したのに、たく悔しいですね。（サイズ後悔）1。）1。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>12279</td>\n",
       "      <td>5</td>\n",
       "      <td>고양이집 만드는데 썻습니다</td>\n",
       "      <td>나는 고양이집을 만드는 것에 지쳤다</td>\n",
       "      <td>고양이집을 만드는 데 닫았습니다</td>\n",
       "      <td>I'm tired of making a cat house.</td>\n",
       "      <td>猫の家を作るのに閉じました</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>7486</td>\n",
       "      <td>5</td>\n",
       "      <td>많이 비치치 않고 길이감도 적당합니다.</td>\n",
       "      <td>그다지 가시적이지 않고, 길이감이 적절하다.</td>\n",
       "      <td>많이 비치지 않고 길이가 적당합니다.</td>\n",
       "      <td>It's not much visible, and the sense of length...</td>\n",
       "      <td>たくさん映らないし、長さが適当です。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>6889</td>\n",
       "      <td>2</td>\n",
       "      <td>철제라 너무 무겁고 혼자 하기는 너무 어렵고 세로 길이가 타이트하면 조립이 어려워 ...</td>\n",
       "      <td>철이라 너무 무거워서 혼자서 하기 힘들고, 길이가 좁으면 조립이 어렵기 때문에 누워...</td>\n",
       "      <td>철제이니까 너무 무거워서 혼자서 하는 것은 지나치게 어렵고 세로의 길이가 타이트하면...</td>\n",
       "      <td>It's too heavy because it's iron, it's too har...</td>\n",
       "      <td>鉄製だから重すぎて、一人でやるのは難しすぎて縦の長さがタイトすると組立が難しくて組み立てて建...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24975 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  target                                            reviews  \\\n",
       "13412  13412       5                     잠자리가 추워서 샀는데 이거때매 회사 지각 몇번했습니다   \n",
       "15013  15013       2        티비서하두멘보샤멘보샤해서궁금해서먹어봤습니다.첨먹엇을땐맛있었는데느끼한맛이강합니다   \n",
       "13297  13297       5  정말튼튼하고 나무재질도 좋습니다 다리부분도 튼튼해요 의자도 너무좋네요 배송은주문제작...   \n",
       "18720  18720       2  배송시까지 일주일걸립니다 당일도착 3일간 오고 결국 일주일뒤에 도착했습니다.통화해보...   \n",
       "20535  20535       2                                       손때및 기스가 잘나요!   \n",
       "...      ...     ...                                                ...   \n",
       "11067  11067       2  이게 바지락인지 재첩인지..ㅠ 백원짜리만하네요...여태 여러군데서 사봤는데 가장 작...   \n",
       "4319    4319       2  xl 사려다 품절이여서 프리사이즈 주문했는데 많이 후회되네요. (사이즈 후회) 1....   \n",
       "12279  12279       5                                     고양이집 만드는데 썻습니다   \n",
       "7486    7486       5                              많이 비치치 않고 길이감도 적당합니다.   \n",
       "6889    6889       2  철제라 너무 무겁고 혼자 하기는 너무 어렵고 세로 길이가 타이트하면 조립이 어려워 ...   \n",
       "\n",
       "                                            en_ko_review  \\\n",
       "13412                       차가운 침대 때문에 샀지만 매번 몇 번이나 늦었다.   \n",
       "15013    TV 서버 하든보 샤멘샤에 대해 궁금증이 많았다. 먹었을 때 맛있었지만 맛이 좋았다.   \n",
       "13297  너는 정말 강하고 목재에 능숙하다 다리가 튼튼하다 그 의자는 너무 좋다 배달은 주문...   \n",
       "18720  배달은 일주일이 걸릴 것이다 그는 이날 사흘 동안 도착해 마침내 일주일 후에 도착했...   \n",
       "20535                                좋은 시간과 좋은 기회가 될 거야!   \n",
       "...                                                  ...   \n",
       "11067  아마도 이것은 바지나 재첩일 것이다 그것은 100원 상당이다. 여러 곳에서 샀지만 ...   \n",
       "4319   xl을 사다가 다 팔렸기 때문에 무료 사이즈 주문을 했는데 정말 죄송합니다. 원스타...   \n",
       "12279                                나는 고양이집을 만드는 것에 지쳤다   \n",
       "7486                            그다지 가시적이지 않고, 길이감이 적절하다.   \n",
       "6889   철이라 너무 무거워서 혼자서 하기 힘들고, 길이가 좁으면 조립이 어렵기 때문에 누워...   \n",
       "\n",
       "                                            jp_ko_review  \\\n",
       "13412                  침대가 추워서 샀는데, 지금까지 회사 지각 몇 번 했습니다.   \n",
       "15013                   텔레비전사 하드멘보셔먼 보셔먼으로 마음에 먹어 보았습니다.   \n",
       "13297  정말 튼튼하고 목재도 좋습니다. 다리 부분도 튼튼해요. 의자도 좋군요. 배송은 주문...   \n",
       "18720    배송시까지 1주일 걸립니다. 당일 도착한 3일간 와서 결국 1주일 후에 도착했습니다.   \n",
       "20535                                     손때와 기스가 좋아집니다.   \n",
       "...                                                  ...   \n",
       "11067     이게 바지야? 100원 정도군요. 지금까지 여러 곳에서 샀는데, 제일 작은 것처럼.   \n",
       "4319   xl을 사려고 해서 프리사이즈를 주문했는데 너무 분하네요. (사이즈 후회) 1. 1...   \n",
       "12279                                  고양이집을 만드는 데 닫았습니다   \n",
       "7486                                많이 비치지 않고 길이가 적당합니다.   \n",
       "6889   철제이니까 너무 무거워서 혼자서 하는 것은 지나치게 어렵고 세로의 길이가 타이트하면...   \n",
       "\n",
       "                                               en_review  \\\n",
       "13412  I bought it because of the cold bed, but I've ...   \n",
       "15013  I've been curious about the TV server Ha Dumen...   \n",
       "13297  You're really strong and you're good with wood...   \n",
       "18720  It'll take a week for delivery. He arrived for...   \n",
       "20535   You're gonna have a good time and a good chance!   \n",
       "...                                                  ...   \n",
       "11067  Maybe this is a pants or a re첩. It's worth a h...   \n",
       "4319   I ordered a free-size order because it was sol...   \n",
       "12279                   I'm tired of making a cat house.   \n",
       "7486   It's not much visible, and the sense of length...   \n",
       "6889   It's too heavy because it's iron, it's too har...   \n",
       "\n",
       "                                               jp_review  \n",
       "13412                      寝床が寒くて買ったんですが、これまで会社遅刻何回しました。  \n",
       "15013  テレビサハドメンボシャメンボッシャーで気に食べてみました。 おいしいときはおいしかったのに感...  \n",
       "13297  本当に丈夫で木材もいいです 足の部分も丈夫です 椅子もいいですね 配送は注問題作で2週ぐらい...  \n",
       "18720  配送時まで1週間かかります。 当日着き3日間来て、結局一週間後に着きました。 電話してみたら...  \n",
       "20535                                      手垢とギスがよくなります。  \n",
       "...                                                  ...  \n",
       "11067  これがズボンか。 百ウォンぐらいですね。 今までいろいろなところで買ってみたのに、一番小さい...  \n",
       "4319   xlを買おうとしたので、プリサイズを注文したのに、たく悔しいですね。（サイズ後悔）1。）1。...  \n",
       "12279                                      猫の家を作るのに閉じました  \n",
       "7486                                  たくさん映らないし、長さが適当です。  \n",
       "6889   鉄製だから重すぎて、一人でやるのは難しすぎて縦の長さがタイトすると組立が難しくて組み立てて建...  \n",
       "\n",
       "[24975 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, valid_dataset = train_test_split(ko_en_jp, random_state=2022, stratify=ko_en_jp['target'], test_size=0.001)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 데이터셋 전처리\n",
    "위의 데이터셋 형태에서 train_test_split을  진행한 후에 한 행에 있는 [원본,영어번역,일본어번역] 3개의 데이터를 3행으로 바꿔주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13412</th>\n",
       "      <td>차가운 침대 때문에 샀지만 매번 몇 번이나 늦었다.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15013</th>\n",
       "      <td>TV 서버 하든보 샤멘샤에 대해 궁금증이 많았다. 먹었을 때 맛있었지만 맛이 좋았다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>너는 정말 강하고 목재에 능숙하다 다리가 튼튼하다 그 의자는 너무 좋다 배달은 주문...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18720</th>\n",
       "      <td>배달은 일주일이 걸릴 것이다 그는 이날 사흘 동안 도착해 마침내 일주일 후에 도착했...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20535</th>\n",
       "      <td>좋은 시간과 좋은 기회가 될 거야!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11067</th>\n",
       "      <td>아마도 이것은 바지나 재첩일 것이다 그것은 100원 상당이다. 여러 곳에서 샀지만 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>xl을 사다가 다 팔렸기 때문에 무료 사이즈 주문을 했는데 정말 죄송합니다. 원스타...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>나는 고양이집을 만드는 것에 지쳤다</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>그다지 가시적이지 않고, 길이감이 적절하다.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>철이라 너무 무거워서 혼자서 하기 힘들고, 길이가 좁으면 조립이 어렵기 때문에 누워...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  target\n",
       "13412                       차가운 침대 때문에 샀지만 매번 몇 번이나 늦었다.       5\n",
       "15013    TV 서버 하든보 샤멘샤에 대해 궁금증이 많았다. 먹었을 때 맛있었지만 맛이 좋았다.       2\n",
       "13297  너는 정말 강하고 목재에 능숙하다 다리가 튼튼하다 그 의자는 너무 좋다 배달은 주문...       5\n",
       "18720  배달은 일주일이 걸릴 것이다 그는 이날 사흘 동안 도착해 마침내 일주일 후에 도착했...       2\n",
       "20535                                좋은 시간과 좋은 기회가 될 거야!       2\n",
       "...                                                  ...     ...\n",
       "11067  아마도 이것은 바지나 재첩일 것이다 그것은 100원 상당이다. 여러 곳에서 샀지만 ...       2\n",
       "4319   xl을 사다가 다 팔렸기 때문에 무료 사이즈 주문을 했는데 정말 죄송합니다. 원스타...       2\n",
       "12279                                나는 고양이집을 만드는 것에 지쳤다       5\n",
       "7486                            그다지 가시적이지 않고, 길이감이 적절하다.       5\n",
       "6889   철이라 너무 무거워서 혼자서 하기 힘들고, 길이가 좁으면 조립이 어렵기 때문에 누워...       2\n",
       "\n",
       "[24975 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각각의 데이터셋에서 review, target을 추출을 진행\n",
    "train, valid = [e[['reviews', 'target']] for e in [train_dataset, valid_dataset]]\n",
    "en_ko_train, en_ko_valid = [e[['en_ko_review', 'target']] for e in [train_dataset, valid_dataset]]\n",
    "jp_ko_train, jp_ko_valid = [e[['jp_ko_review', 'target']] for e in [train_dataset, valid_dataset]]\n",
    "\n",
    "en_ko_train.columns = ['reviews', 'target']\n",
    "en_ko_valid.columns = ['reviews', 'target']\n",
    "jp_ko_train.columns = ['reviews', 'target']\n",
    "jp_ko_valid.columns = ['reviews', 'target']\n",
    "en_ko_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 25000개의 행을 3개를 concat함수를 활용하여 75000개의 데이터셋으로 변형\n",
    "# 원본데이터롤 진행하려면 train, valid만 활용\n",
    "all_train = pd.concat([train, en_ko_train, jp_ko_train], ignore_index=True)\n",
    "all_valid = pd.concat([valid, en_ko_valid, jp_ko_valid], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-24f77f946c60edab\n",
      "Reusing dataset csv (/home/uj-user/.cache/huggingface/datasets/csv/default-24f77f946c60edab/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1531003c834e17b1617195dbcd228e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 허깅페이스 데이터셋을 활용하여, 데이터셋 로드 \n",
    "raw_train = Dataset.from_pandas(all_train)\n",
    "raw_valid = Dataset.from_pandas(all_valid)\n",
    "raw_test = load_dataset('csv', data_files='./dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['reviews', 'target'],\n",
       "        num_rows: 74925\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['reviews', 'target'],\n",
       "        num_rows: 75\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'reviews'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 따로 불러들인 train,valid,test데이터셋을 하나의 DatasetDict로 합치기\n",
    "review_dataset = datasets.DatasetDict({'train': raw_train, 'valid': raw_valid, 'test': raw_test['train']})\n",
    "review_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 허깅페이스 데이터셋 로드 & 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_function at 0x7f1ebe8a1160> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['조아', ',', '처음으로', '싸게', '샀', '##어']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d5ce14303643409a266afb5cdd46c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46627c05da7489f80d65a09539445ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feea78f067ea402ba59ba5616413a2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 사용할 모델의 토크나이저로 테스트 및 모델의 입력가능한 형태로 변형\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(tokenizer.tokenize(en_ko_train['reviews'][0]))\n",
    "\n",
    "def preprocess_function(example):\n",
    "    return tokenizer(example[\"reviews\"], truncation=True)\n",
    "    \n",
    "tokenized_datasets = review_dataset.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['reviews', 'target', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 74925\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['reviews', 'target', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 75\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'reviews', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 데이터셋에서 필요없는 Column 삭제 (id, reviews)\n",
    "tokenized_datasets['train'] = tokenized_datasets['train'].remove_columns([\"reviews\"])\n",
    "tokenized_datasets['valid'] = tokenized_datasets['valid'].remove_columns([\"reviews\"])\n",
    "tokenized_datasets['test'] = tokenized_datasets['test'].remove_columns([\"id\", \"reviews\"])\n",
    "\n",
    "# 정답 columns이름을 target에서 labels로 변경\n",
    "tokenized_datasets['train'] = tokenized_datasets['train'].rename_column(\"target\", \"labels\")\n",
    "tokenized_datasets['valid'] = tokenized_datasets['valid'].rename_column(\"target\", \"labels\")\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator)\n",
    "valid_dataloader = DataLoader(tokenized_datasets[\"valid\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"test\"], shuffle=False, batch_size=batch_size, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([200]),\n",
       " 'input_ids': torch.Size([200, 52]),\n",
       " 'token_type_ids': torch.Size([200, 52]),\n",
       " 'attention_mask': torch.Size([200, 52])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kykim/electra-kor-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at kykim/electra-kor-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=6) # 편의상 6으로 설정/ (1,2,4,5)만 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uj-user/miniconda3/envs/review/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler, AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_training_steps = NUM_EPOCH * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51449360f564f6aa7f3b5caeb955f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    model.save_pretrained(f\"./aug_result/{MODEL_NAME}/{epoch+1}\")\n",
    "    tokenizer.save_pretrained(f\"./aug_result/{MODEL_NAME}/{epoch+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "# validataion 데이터셋을 활용하여 모델 검증\n",
    "def validation_model(model):\n",
    "    accuracy = Accuracy()\n",
    "    prediction_list_valid = []\n",
    "    target_list_valid = []\n",
    "\n",
    "    model.eval()\n",
    "    for batch in valid_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1).cpu()\n",
    "        targets = batch['labels'].cpu()\n",
    "\n",
    "        prediction_list_valid.extend(predictions)\n",
    "        target_list_valid.extend(targets)\n",
    "    print(f'valid acc: {accuracy(torch.IntTensor(prediction_list_valid), torch.IntTensor(target_list_valid)).cpu().tolist():.4f}')\n",
    "\n",
    "# train 데이터셋을 활용하여 validation결과와 차이 비교\n",
    "def validation_train_model(model):\n",
    "    accuracy = Accuracy()\n",
    "    prediction_list_valid = []\n",
    "    target_list_valid = []\n",
    "\n",
    "    model.eval()\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1).cpu()\n",
    "        targets = batch['labels'].cpu()\n",
    "\n",
    "        prediction_list_valid.extend(predictions)\n",
    "        target_list_valid.extend(targets)\n",
    "    print(f'train acc: {accuracy(torch.IntTensor(prediction_list_valid), torch.IntTensor(target_list_valid)).cpu().tolist():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:model >> ./aug_result/kykim/electra-kor-base/1\n",
      "valid acc: 0.6667\n",
      "2:model >> ./aug_result/kykim/electra-kor-base/2\n",
      "valid acc: 0.6133\n",
      "3:model >> ./aug_result/kykim/electra-kor-base/3\n",
      "valid acc: 0.6000\n",
      "4:model >> ./aug_result/kykim/electra-kor-base/4\n",
      "valid acc: 0.6000\n",
      "5:model >> ./aug_result/kykim/electra-kor-base/5\n",
      "valid acc: 0.6000\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델을 활용하여 Validation 데이터셋에서 성능확인\n",
    "save_paths = sorted(glob(f\"./aug_result/{MODEL_NAME}/*\"))\n",
    "for i, save_path in enumerate(save_paths):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=6).to(device)\n",
    "    print(f\"{i+1}:model >> {save_path}\")\n",
    "    validation_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:model >> ./aug_result/kykim/electra-kor-base/1\n",
      "train acc: 0.6877\n",
      "2:model >> ./aug_result/kykim/electra-kor-base/2\n",
      "train acc: 0.7069\n",
      "3:model >> ./aug_result/kykim/electra-kor-base/3\n",
      "train acc: 0.7222\n",
      "4:model >> ./aug_result/kykim/electra-kor-base/4\n",
      "train acc: 0.7351\n",
      "5:model >> ./aug_result/kykim/electra-kor-base/5\n",
      "train acc: 0.7407\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델을 활용하여 Train 데이터셋에서 성능확인\n",
    "save_paths = sorted(glob(f\"./aug_result/{MODEL_NAME}/*\"))\n",
    "for i, save_path in enumerate(save_paths):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=6).to(device)\n",
    "    print(f\"{i+1}:model >> {save_path}\")\n",
    "    validation_train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train데이터셋과 Validation데이터셋에 모델의 결과를 확인한결과 1~2에폭에서 오버피팅이 발생 (정확한 검증을 위해서는 train_test_split에서 test_size=0.1이상으로 설정 권장)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 Evaluation 및 Submission 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_submit_model(model, eval_epoch):\n",
    "    prediction_list = []\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        prediction_list.extend(predictions.cpu().tolist())\n",
    "\n",
    "    submission = pd.read_csv(\"dataset/sample_submission.csv\")\n",
    "    submission[\"target\"] = prediction_list\n",
    "    submission.to_csv(f\"./submission/submission_{MODEL_NAME.replace('/', '_')}_{eval_epoch}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 에폭별 제출 코드 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:model >> ./aug_result/kykim/electra-kor-base/1\n",
      "2:model >> ./aug_result/kykim/electra-kor-base/2\n",
      "3:model >> ./aug_result/kykim/electra-kor-base/3\n",
      "4:model >> ./aug_result/kykim/electra-kor-base/4\n",
      "5:model >> ./aug_result/kykim/electra-kor-base/5\n"
     ]
    }
   ],
   "source": [
    "save_paths = sorted(glob(f\"./aug_result/{MODEL_NAME}/*\"))\n",
    "for i, save_path in enumerate(save_paths):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=6).to(device)\n",
    "    print(f\"{i+1}:model >> {save_path}\")\n",
    "    evaluate_submit_model(model, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 앙상블 코드 생성\n",
    "\n",
    "2에서 6과정에서 생성된 다수의 제출파일을 활용하여 Hard Voting을 진행합니다.   \n",
    "모델은 5개로 선정, 데이터셋은 [원본(25000), 전제Aug(75000)] 두가지를 선정하여, 총 5개의 csv파일을 선정하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval1 = pd.read_csv('./submission/submission_klue_bert-base_2.csv') # 원본\n",
    "df_eval2 = pd.read_csv('./submission/submission_klue_roberta-large_2.csv') # 전제Aug\n",
    "df_eval3 = pd.read_csv('./submission/submission_kykim_bert-kor-base_2.csv') # 전제Aug\n",
    "df_eval4 = pd.read_csv('./submission/submission_kykim_electra-kor-base_2.csv') # 원본\n",
    "df_eval5 = pd.read_csv('./submission/submission_kykim_funnel-kor-base_2.csv') #전제Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review1</th>\n",
       "      <th>review2</th>\n",
       "      <th>review3</th>\n",
       "      <th>review4</th>\n",
       "      <th>review5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       review1  review2  review3  review4  review5\n",
       "0            2        2        2        2        2\n",
       "1            1        1        1        1        1\n",
       "2            5        5        5        5        5\n",
       "3            1        1        1        1        1\n",
       "4            1        1        1        1        1\n",
       "...        ...      ...      ...      ...      ...\n",
       "24995        5        5        5        5        5\n",
       "24996        5        5        5        5        5\n",
       "24997        2        2        1        2        1\n",
       "24998        5        5        5        5        5\n",
       "24999        2        1        1        2        2\n",
       "\n",
       "[25000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dict = {'review1': df_eval1['target'], 'review2': df_eval2['target'], 'review3': df_eval3['target'], 'review4': df_eval4['target'], 'review5': df_eval5['target']}\n",
    "df_ensemble = pd.DataFrame(target_dict)\n",
    "df_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def ensemble_data(data):\n",
    "    # 1. 매열마다 모든 값을 Count, 가장 많은 빈도의 값을 추출.\n",
    "    result_list = []\n",
    "    for i in range(len(data)):\n",
    "        frequent_value = data.iloc[i].value_counts().idxmax()\n",
    "        result_list.append(frequent_value)\n",
    "    return pd.DataFrame({'target':result_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target\n",
       "0           2\n",
       "1           1\n",
       "2           5\n",
       "3           1\n",
       "4           1\n",
       "...       ...\n",
       "24995       5\n",
       "24996       5\n",
       "24997       2\n",
       "24998       5\n",
       "24999       2\n",
       "\n",
       "[25000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ensemble_data(df_ensemble)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출용 파일 불러오기\n",
    "submission = pd.read_csv(\"dataset/sample_submission.csv\") \n",
    "submission.head() \n",
    "\n",
    "# 예측 값 넣어주기\n",
    "submission[\"target\"] = result\n",
    "submission.to_csv('./submission/submission_ensemble5_epoch2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('review': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62924353be2d6998b04c83d0e210e35559f7d4fed57bef9b7971c9483623c7fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
